{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dan Crouthamel – SMU NLP Course — Homework 4\n",
    "\n",
    "## Assignment Objectives\n",
    "\n",
    "1.\tRun one of the part-of-speech (POS) taggers available in Python.  \n",
    "* Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n",
    "* Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n",
    "\n",
    "2.  Run a different tagger in Python. Process the same two sentences from Question 1.\n",
    "* Does it produce the same or different output?\n",
    "\n",
    "* Explain any differences as best as you can.\n",
    "\n",
    "3.  In a news article from this week's news, find a random sentence of at least 10 words.\n",
    "* Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "\n",
    "* Now run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    "\n",
    "* Explain any differences between the two taggers and your manual tagging as much as you can.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/30821188/python-nltk-pos-tag-not-returning-the-correct-part-of-speech-tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 and 2\n",
    "\n",
    "For **Question 1**, we'll use the nltk.pos_tag function to determine part of speech. Under the covers, this is using a Perceptron tagger and comes with a pretrained model, trained and tested on parts of a Wall Street Jounal corpus. For more information, see the links below. \n",
    "\n",
    "https://stackoverflow.com/questions/32016545/how-does-nltk-pos-tag-work/41384824\n",
    "https://www.kaggle.com/nltkdata/averaged-perceptron-tagger\n",
    "\n",
    "For **Question 2**, we will use the Spacy tagger and then compare the results with the output form Question 1. The model we will use for Spacy is 'en_core_web_sm', which is a small English pipeline trained on written web text (blogs, news, and comments).\n",
    "\n",
    "https://spacy.io/api/tagger  \n",
    "https://spacy.io/models\n",
    "\n",
    "Let's define a long text and short text. The long text is taken from a recent Wall Street journal article. The short text is something I came up with to see if the taggers get it correct.\n",
    "\n",
    "**Long Text** -> \"More U.S. workers are quitting their jobs than at any time in at least two decades, signaling optimism among many professionals while also adding to the struggle companies face trying to keep up with the economic recovery.\"  \n",
    "\n",
    "**Short Text** -> \"Women need men like fish need bicycles.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Word NLTK TAG Spacy Tag\n",
       "0            More      JJR       JJR\n",
       "1            U.S.      NNP       NNP\n",
       "2         workers      NNS       NNS\n",
       "3             are      VBP       VBP\n",
       "4        quitting      VBG       VBG\n",
       "5           their     PRP$      PRP$\n",
       "6            jobs      NNS       NNS\n",
       "7            than       IN        IN\n",
       "8              at       IN        IN\n",
       "9             any       DT        DT\n",
       "10           time       NN        NN\n",
       "11             in       IN        IN\n",
       "12             at       IN        RB\n",
       "13          least      JJS       RBS\n",
       "14            two       CD        CD\n",
       "15        decades      NNS       NNS\n",
       "16              ,        ,         ,\n",
       "17      signaling      VBG       VBG\n",
       "18       optimism       NN        NN\n",
       "19          among       IN        IN\n",
       "20           many       JJ        JJ\n",
       "21  professionals      NNS       NNS\n",
       "22          while       IN        IN\n",
       "23           also       RB        RB\n",
       "24         adding      VBG       VBG\n",
       "25             to       TO        IN\n",
       "26            the       DT        DT\n",
       "27       struggle       NN        NN\n",
       "28      companies      NNS       NNS\n",
       "29           face      VBP       VBP\n",
       "30         trying      VBG       VBG\n",
       "31             to       TO        TO\n",
       "32           keep       VB        VB\n",
       "33             up       RP        RP\n",
       "34           with       IN        IN\n",
       "35            the       DT        DT\n",
       "36       economic       JJ        JJ\n",
       "37       recovery       NN        NN\n",
       "38              .        .         ."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NLTK TAG</th>\n      <th>Spacy Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>More</td>\n      <td>JJR</td>\n      <td>JJR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S.</td>\n      <td>NNP</td>\n      <td>NNP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>workers</td>\n      <td>NNS</td>\n      <td>NNS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>are</td>\n      <td>VBP</td>\n      <td>VBP</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>quitting</td>\n      <td>VBG</td>\n      <td>VBG</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>their</td>\n      <td>PRP$</td>\n      <td>PRP$</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>jobs</td>\n      <td>NNS</td>\n      <td>NNS</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>than</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>at</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>any</td>\n      <td>DT</td>\n      <td>DT</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>time</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>in</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>at</td>\n      <td>IN</td>\n      <td>RB</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>least</td>\n      <td>JJS</td>\n      <td>RBS</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>two</td>\n      <td>CD</td>\n      <td>CD</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>decades</td>\n      <td>NNS</td>\n      <td>NNS</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>,</td>\n      <td>,</td>\n      <td>,</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>signaling</td>\n      <td>VBG</td>\n      <td>VBG</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>optimism</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>among</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>many</td>\n      <td>JJ</td>\n      <td>JJ</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>professionals</td>\n      <td>NNS</td>\n      <td>NNS</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>while</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>also</td>\n      <td>RB</td>\n      <td>RB</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>adding</td>\n      <td>VBG</td>\n      <td>VBG</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>to</td>\n      <td>TO</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>the</td>\n      <td>DT</td>\n      <td>DT</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>struggle</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>companies</td>\n      <td>NNS</td>\n      <td>NNS</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>face</td>\n      <td>VBP</td>\n      <td>VBP</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>trying</td>\n      <td>VBG</td>\n      <td>VBG</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>to</td>\n      <td>TO</td>\n      <td>TO</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>keep</td>\n      <td>VB</td>\n      <td>VB</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>up</td>\n      <td>RP</td>\n      <td>RP</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>with</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>the</td>\n      <td>DT</td>\n      <td>DT</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>economic</td>\n      <td>JJ</td>\n      <td>JJ</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>recovery</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "sentence = \"More U.S. workers are quitting their jobs than at any time in at least two decades, signaling optimism among many professionals while also adding to the struggle companies face trying to keep up with the economic recovery.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "text = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Create a data frame and add the Word column\n",
    "columns = ['Word','NLTK TAG','Spacy Tag']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df['Word'] = text\n",
    "\n",
    "# Create NLTK Tag Column derived from pos_tag\n",
    "col_vals = [tag[1] for tag in nltk.pos_tag(text)]\n",
    "df['NLTK TAG'] = col_vals\n",
    "\n",
    "# Create Spacy Tag Column derived from Spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "col_vals = [word.tag_ for word in sp(sentence)]\n",
    "df['Spacy Tag'] = col_vals\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference that can be seen between the two taggers is line 25. NLTK classifies 'to' as TO, but Spacy classes it as IN. IN is a preposition, and so is the word 'to'. I'm not sure why Spacy didn't classify it as TO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               0     1    2     3     4     5         6  7\n",
       "Word       Women  need  men  like  fish  need  bicycles  .\n",
       "NLTK TAG     NNS   VBP  NNS    IN    JJ    NN       NNS  .\n",
       "Spacy Tag    NNS   VBP  NNS    IN    NN   VBP       NNS  ."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Word</th>\n      <td>Women</td>\n      <td>need</td>\n      <td>men</td>\n      <td>like</td>\n      <td>fish</td>\n      <td>need</td>\n      <td>bicycles</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>NLTK TAG</th>\n      <td>NNS</td>\n      <td>VBP</td>\n      <td>NNS</td>\n      <td>IN</td>\n      <td>JJ</td>\n      <td>NN</td>\n      <td>NNS</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>Spacy Tag</th>\n      <td>NNS</td>\n      <td>VBP</td>\n      <td>NNS</td>\n      <td>IN</td>\n      <td>NN</td>\n      <td>VBP</td>\n      <td>NNS</td>\n      <td>.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "sentence = \"Women need men like fish need bicycles.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "text = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Create a data frame and add the Word column\n",
    "columns = ['Word','NLTK TAG','Spacy Tag']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df['Word'] = text\n",
    "\n",
    "# Create NLTK Tag Column derived from pos_tag\n",
    "col_vals = [tag[1] for tag in nltk.pos_tag(text)]\n",
    "df['NLTK TAG'] = col_vals\n",
    "\n",
    "# Create Spacy Tag Column derived from Spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "col_vals = [word.tag_ for word in sp(sentence)]\n",
    "df['Spacy Tag'] = col_vals\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For question 2, I tried to come up with a short sentence in which I thought could trip things up. NLTK did not get the POS correct for the words 'fish\" and 'need', but Spacy did. I supspect this is primarily due to what information the Perceptron and Spacy taggers were trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "The sentence I chose is from the following article linked below.\n",
    "\n",
    "\"Last December, as part of the omnibus spending and coronavirus relief package, Congress stipulated a report conducted by multiple agencies must be handed over this month with detailed analysis of UAP sightings by U.S. military members.\"\n",
    "\n",
    "https://www.washingtonpost.com/washington-post-live/2021/06/08/ufos-national-security-with-luis-elizondo-former-director-advanced-aerospace-threat-identification-program-aatip/\n",
    "\n",
    "In the code below I created a column with my manual tagging, based on my limited grammar skills. This is based on the tags defined below. I then combine that with the output from NLTK pos_tag and Spacy.\n",
    "\n",
    "https://www.sketchengine.eu/penn-treebank-tagset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Word NLTK TAG Spacy Tag Dan's Tag\n",
       "0          Last       JJ        JJ        JJ\n",
       "1      December      NNP       NNP        NN\n",
       "2             ,        ,         ,         ,\n",
       "3            as       IN        IN        IN\n",
       "4          part       NN        NN        NN\n",
       "5            of       IN        IN        IN\n",
       "6           the       DT        DT        DT\n",
       "7       omnibus       JJ        JJ        JJ\n",
       "8      spending       NN        NN        NN\n",
       "9           and       CC        CC        CC\n",
       "10  coronavirus       NN        NN        NN\n",
       "11       relief       NN        NN        NN\n",
       "12      package       NN        NN        NN\n",
       "13            ,        ,         ,         ,\n",
       "14     Congress      NNP       NNP       NNP\n",
       "15   stipulated      VBD       VBD       VBD\n",
       "16            a       DT        DT        DT\n",
       "17       report       NN        NN        NN\n",
       "18    conducted      VBN       VBN       VBD\n",
       "19           by       IN        IN        IN\n",
       "20     multiple       JJ        JJ        JJ\n",
       "21     agencies      NNS       NNS       NNS\n",
       "22         must       MD        MD        ??\n",
       "23           be       VB        VB        VB\n",
       "24       handed      VBN       VBN        VB\n",
       "25         over       RP        RP        IN\n",
       "26         this       DT        DT        DT\n",
       "27        month       NN        NN        NN\n",
       "28         with       IN        IN        IN\n",
       "29     detailed       JJ        JJ        JJ\n",
       "30     analysis       NN        NN        NN\n",
       "31           of       IN        IN        IN\n",
       "32          UAP      NNP       NNP       NNP\n",
       "33    sightings      NNS       NNS       NNS\n",
       "34           by       IN        IN        IN\n",
       "35         U.S.      NNP       NNP       NNP\n",
       "36     military       JJ        JJ        JJ\n",
       "37      members      NNS       NNS       NNS\n",
       "38            .        .         .         ."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NLTK TAG</th>\n      <th>Spacy Tag</th>\n      <th>Dan's Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last</td>\n      <td>JJ</td>\n      <td>JJ</td>\n      <td>JJ</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>December</td>\n      <td>NNP</td>\n      <td>NNP</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>,</td>\n      <td>,</td>\n      <td>,</td>\n      <td>,</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>as</td>\n      <td>IN</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>part</td>\n      <td>NN</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>of</td>\n      <td>IN</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>the</td>\n      <td>DT</td>\n      <td>DT</td>\n      <td>DT</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>omnibus</td>\n      <td>JJ</td>\n      <td>JJ</td>\n      <td>JJ</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>spending</td>\n      <td>NN</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>and</td>\n      <td>CC</td>\n      <td>CC</td>\n      <td>CC</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>coronavirus</td>\n      <td>NN</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>relief</td>\n      <td>NN</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>package</td>\n      <td>NN</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>,</td>\n      <td>,</td>\n      <td>,</td>\n      <td>,</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Congress</td>\n      <td>NNP</td>\n      <td>NNP</td>\n      <td>NNP</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>stipulated</td>\n      <td>VBD</td>\n      <td>VBD</td>\n      <td>VBD</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>a</td>\n      <td>DT</td>\n      <td>DT</td>\n      <td>DT</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>report</td>\n      <td>NN</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>conducted</td>\n      <td>VBN</td>\n      <td>VBN</td>\n      <td>VBD</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>by</td>\n      <td>IN</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>multiple</td>\n      <td>JJ</td>\n      <td>JJ</td>\n      <td>JJ</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>agencies</td>\n      <td>NNS</td>\n      <td>NNS</td>\n      <td>NNS</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>must</td>\n      <td>MD</td>\n      <td>MD</td>\n      <td>??</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>be</td>\n      <td>VB</td>\n      <td>VB</td>\n      <td>VB</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>handed</td>\n      <td>VBN</td>\n      <td>VBN</td>\n      <td>VB</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>over</td>\n      <td>RP</td>\n      <td>RP</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>this</td>\n      <td>DT</td>\n      <td>DT</td>\n      <td>DT</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>month</td>\n      <td>NN</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>with</td>\n      <td>IN</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>detailed</td>\n      <td>JJ</td>\n      <td>JJ</td>\n      <td>JJ</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>analysis</td>\n      <td>NN</td>\n      <td>NN</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>of</td>\n      <td>IN</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>UAP</td>\n      <td>NNP</td>\n      <td>NNP</td>\n      <td>NNP</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>sightings</td>\n      <td>NNS</td>\n      <td>NNS</td>\n      <td>NNS</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>by</td>\n      <td>IN</td>\n      <td>IN</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>U.S.</td>\n      <td>NNP</td>\n      <td>NNP</td>\n      <td>NNP</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>military</td>\n      <td>JJ</td>\n      <td>JJ</td>\n      <td>JJ</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>members</td>\n      <td>NNS</td>\n      <td>NNS</td>\n      <td>NNS</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "sentence = \"Last December, as part of the omnibus spending and coronavirus relief package, Congress stipulated a report conducted by multiple agencies must be handed over this month with detailed analysis of UAP sightings by U.S. military members.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "text = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Create a data frame and add the Word column\n",
    "columns = ['Word','NLTK TAG','Spacy Tag',\"Dan's Tag\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df['Word'] = text\n",
    "\n",
    "# Create NLTK Tag Column derived from pos_tag\n",
    "col_vals = [tag[1] for tag in nltk.pos_tag(text)]\n",
    "df['NLTK TAG'] = col_vals\n",
    "\n",
    "# Create Spacy Tag Column derived from Spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "col_vals = [word.tag_ for word in sp(sentence)]\n",
    "df['Spacy Tag'] = col_vals\n",
    "\n",
    "df[\"Dan's Tag\"] = ['JJ', 'NN', ',', 'IN', 'NN', 'IN', 'DT', 'JJ', 'NN', 'CC', \\\n",
    "                   'NN', 'NN', 'NN', ',', 'NNP', 'VBD', 'DT', 'NN', 'VBD', 'IN', \\\n",
    "                   'JJ', 'NNS', '??', 'VB', 'VB', 'IN', 'DT', 'NN', 'IN', 'JJ', \\\n",
    "                   'NN', 'IN', 'NNP', 'NNS', 'IN', 'NNP', 'JJ', 'NNS', '.'\n",
    "                  ]\n",
    "    \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that the NLTK and Spacy taggers returned the same results. However, my tagging is not the same, primarily because I have forgotten some rules of grammar. Here are some of the things I missed.\n",
    "\n",
    "* December - Classified as noun (NN), instead of proper noun (NP)\n",
    "* Conducted - Classified as past tense verb (VBD), instead of past participle (VBN)\n",
    "* Must - I didn't know how to classify this. Spacy and pos_tag returned modal (MD), which I believe is the same as a helping verb.\n",
    "* Over - Classified as a preposition (IN), instead of particle.\n",
    "\n",
    "What is a particle part of speach? A word that doesn't fit into one of the traditional 8 parts of speech.\n",
    "For example, a noun, verb, pronoun, adjective, preposition, adverb, interjection, or conjunction. See link below.\n",
    "\n",
    "So to conclude, I'd be more comfortable relying on the taggers to do the work for me :)\n",
    "\n",
    "https://www.gingersoftware.com/content/particle-grammar/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('NLP': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "68ee3ae78084525ade826e2d5a652ba1e501f843acd4bb4fc224fb18fd05eb6b"
   }
  },
  "orig_nbformat": 3,
  "interpreter": {
   "hash": "eaa798b471aa1a0109429a408b0faab53065248ef7f5a5989f90756771672ef6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}