{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "scheduled-gabriel",
   "metadata": {},
   "source": [
    "# Dan Crouthamel – SMU NLP Course — Homework 3\n",
    "\n",
    "## Assignment Objectives\n",
    "\n",
    "1. Compare your given name with your nickname (if you don’t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "* What is the edit distance between your nickname and your given name?\n",
    "* What is the percentage string match between your nickname and your given name?  \n",
    "\n",
    "  Show your work for both calculations\n",
    "\n",
    "2. Find a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words\n",
    "\n",
    "3. Run one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-turtle",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "persistent-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import edit_distance\n",
    "from nltk.tokenize import word_tokenize\n",
    "from difflib import SequenceMatcher\n",
    "import re"
   ]
  },
  {
   "source": [
    "### Question 1\n",
    "\n",
    "To compute the edit distance metric, we'll use the edit_distance metric function, which computes the Levenshtein edit distance between two strings. The edit distance is the number of characters that need to be substituted, inserted, or deleted, to transform one string into another.\n",
    "\n",
    "https://www.nltk.org/api/nltk.metrics.html\n",
    "\n",
    "My given name is Daniel, but growing up I went by the name of Danny. Today most people call me Dan. Below we can see that the edit distance between my full name and either nickname is 3."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The edit distance between Daniel and Danny: 3\nThe edit distance between Daniel and Dan: 3\n"
     ]
    }
   ],
   "source": [
    "fullName = 'Daniel'\n",
    "nick1 = 'Danny'\n",
    "nick2 = 'Dan'\n",
    "\n",
    "print('The edit distance between Daniel and Danny:', edit_distance(fullName,nick1))\n",
    "print('The edit distance between Daniel and Dan:', edit_distance(fullName,nick2))\n",
    "\n"
   ]
  },
  {
   "source": [
    "To compute the percentage string match, I used the SequenceMatcher function based on info from the below article.\n",
    "\n",
    "https://stackoverflow.com/questions/17388213/find-the-similarity-metric-between-two-strings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percent String Match between Daniel and Danny -> 55%\nPrecent String Match between Daniel and Dan -> 67%\n"
     ]
    }
   ],
   "source": [
    "print('Percent String Match between Daniel and Danny -> {0:.0%}'.format(SequenceMatcher(None, fullName, nick1).ratio()))\n",
    "print('Precent String Match between Daniel and Dan -> {0:.0%}'.format(SequenceMatcher(None, fullName, nick2).ratio()))"
   ]
  },
  {
   "source": [
    "### Question 2\n",
    "\n",
    "The book I choose from my fiancé’s reading list was \"The Kite Runner\", by Khaled Hosseini. The first two sentences are below.\n",
    "\n",
    "\"I became what I am today at the age of twelve, on a frigid overcast day in the winter of 1975. I remember the precise moment, crouching behind a crumbling mud wall, peeking into the alley near the frozen creek.\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOriginal Words\n['I', 'became', 'what', 'I', 'am', 'today', 'at', 'the', 'age', 'of', 'twelve', 'on', 'a', 'frigid', 'overcast', 'day', 'in', 'the', 'winter', 'of', '1975', 'I', 'remember', 'the', 'precise', 'moment', 'crouching', 'behind', 'a', 'crumbling', 'mud', 'wall', 'peeking', 'into', 'the', 'alley', 'near', 'the', 'frozen', 'creek']\n\nFirst two sentences with stop words removed.\n['became', 'today', 'age', 'twelve', 'frigid', 'overcast', 'day', 'winter', '1975', 'remember', 'precise', 'moment', 'crouching', 'behind', 'crumbling', 'mud', 'wall', 'peeking', 'alley', 'near', 'frozen', 'creek']\n"
     ]
    }
   ],
   "source": [
    "kite_book = \"I became what I am today at the age of twelve, on a frigid overcast day in the winter of 1975. I remember the precise moment, crouching behind a crumbling mud wall, peeking into the alley near the frozen creek.\"\n",
    "\n",
    "# Remove punctuation\n",
    "# https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
    "kite_book = re.sub(r'[^\\w\\s]+', '', kite_book)\n",
    "\n",
    "# Define stop words\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Tokenize the sentences\n",
    "kite_tokens = word_tokenize(kite_book)\n",
    "\n",
    "# Remove stop words from sentences\n",
    "kite_tokens_no_stop_words = [w for w in kite_tokens if w.lower() not in stopwords]\n",
    "\n",
    "print(\"\")\n",
    "print(\"Original Words\")\n",
    "print(kite_tokens)\n",
    "\n",
    "print(\"\")\n",
    "print(\"First two sentences with stop words removed.\")\n",
    "print(kite_tokens_no_stop_words)\n"
   ]
  },
  {
   "source": [
    "My girlfriend, Joy, did guess the book on the first try, and was surprised that she did. She couldn't say why, other than maybe becuase the story is about a little boy. I've never read the book, but did see the movie years ago.\n",
    "\n",
    "Joy's native language is Korean, and after discussing the Stop Words concept with her she mentioned that they don't really exist in Korean. She feels that English is a very inefficient language. Perhaps she is correct :) I wonder if there is a language that has symbols that can encapsulate an entire paragraph? Something that you can experience in a single thought or moment, rather than sounding out a bunch of syllables and taking too much time."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 3\n",
    "\n",
    "For question 3, I'll use the Porter stemmer. We'll then compare that output with nltk.corpus.words, to see if it's a valid word. I'm not sure those if that really answers the question that is is a valid morpholicial root, but it's the best I can think of for now. If there is anything better, please let me know! \n",
    "\n",
    "https://www.nltk.org/api/nltk.stem.html\n",
    "\n",
    "With the approach outlined above, we see that the Percentage of stems that are valid words is 77%. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['becam', 'today', 'age', 'twelv', 'frigid', 'overcast', 'day', 'winter', '1975', 'rememb', 'precis', 'moment', 'crouch', 'behind', 'crumbl', 'mud', 'wall', 'peek', 'alley', 'near', 'frozen', 'creek']\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "new_text = [porter.stem(w) for w in kite_tokens_no_stop_words]\n",
    "\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage of stems that are valid words -> 77%\n"
     ]
    }
   ],
   "source": [
    "# Import valid words here to compare our stems against\n",
    "from nltk.corpus import words\n",
    "\n",
    "valid_words = [word for word in new_text if word in words.words()]\n",
    "\n",
    "print(\"Percentage of stems that are valid words -> {0:.0%}\".format(len(valid_words)/len(new_text)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd068ee3ae78084525ade826e2d5a652ba1e501f843acd4bb4fc224fb18fd05eb6b",
   "display_name": "Python 3.7.6 64-bit ('ML7331': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "68ee3ae78084525ade826e2d5a652ba1e501f843acd4bb4fc224fb18fd05eb6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}